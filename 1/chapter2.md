# CHAPTER 2 INTEL® 64 AND IA-32 ARCHITECTURES

# 2.1 BRIEF HISTORY OF INTEL® 64 AND IA-32 ARCHITECTURE
다음 섹션들은 IA-32에서 Intel 64 아키텍처까지의 주요한 기술 진화의 요약을 제공한다: 8086프로세서 최신  Intel® Core® 2 Duo, Core 2 Quad and Intel Xeon processor 5300 and 7300 series 까지. 1978년도용 프로세서용으로 만들어진 오브젝트 코드는 최신 Intel64 IA-32아키텍처군에서도 실행된다.

## 2.1.1~2.1.22 CPU발전 역사, 생략

# 2.2 MORE ON SPECIFIC ADVANCES
이 부분부터는 주요한 발전에 대한 정보다

## 2.2.1 P6 Family Microarchitecture
펜티엄 프로 프로세서는 P6 프로세서 마이크로아키텍처로 불리는 새로운 마이크로아키텍처를 도입했다. P6 프로세서 마이크로아키텍처는 나중에 Advancded Transfer Cache라고 불리는 on-die Level 2 cache로 성능이 개선되었다.
이 마이크로아키텍처는 3중 슈퍼스칼라, 파이프라인 아키텍처다. 3중 슈퍼스칼라는 병령 처리 기법을 사용하여, 프로세서가 평균적으로 decode, dispatch, complete execution의 3가지 명령어들을 한 클럭에 실행하는 것을 의미한다. 이정도 수준의 명령어 처리량을 다루기 위해, 분리된 12단계 슈퍼 파이프라인을 사용하는데, 비순차적 명령어 처리을 지원한다.
Figure 2-1은 Advancded Transfer Cache enhancement가 사용된 P6 마이크로아키텍처 파이프라인의 개념도를 보여준다.
명령어 실행 파이프라인에 지속적인 명령어와 데이터를 보장하기 위해서, P6 프로세서 마이크로아키텍처는 2개의 캐시 레벨을 합쳤다. Level 1 캐쉬는 8KB의 명령어 캐쉬와 8KB의 데이터 캐쉬를 제공한다, 두 캐쉬는 파이프라인과 가까히 결합되있다. Level 2 캐쉬는 256KB, 512KB, 또는 1MB의 정적 램을 제공하는데 full clock-speed 64비트 캐쉬 버스와 결합되 있다.
P6 프로세서 마이크로아키텍처의 핵심은 동적 실행이라고 불리는 비순차적 명령어 처리 기법이다. 동적 실행은 3개의 데이터 처리 개념이 결합되있다:
- **깊은 분기 예측** 프로세서가 분기 이후의 명령어들을 해독할 해서 명령어 파이프라인을 최대로 유지할 수 있게 해준다. P6 프로세서 패밀리는 명령어의 방향을 예측하는 매우 최적화된 분기 예측 알고리즘을 구현했다.
- **동적 데이터 흐름 분석**은 프로세서가 의존성을 결정하고 비순차적 명령어 처리의 기회를 발견하기 위한 실시간 데이터 흐름 분석을 필요로 한다. 비순차적 명령어 실행 코어는 많은 명령어들을 감시하고 이러한 명령어들을 프로세서의 다중 실행 유닛을 사용하여 가장 최적화된 순서로 실행시킬 수 있게 해주는데, 데이터의 무결성을 유지한다.
- **추측 실행** 은 조건 분기 뒤의 아직 분기되지 않은 명령어들을 프로세서가 실행시킬 수 있는 능력을 가르키는데, 궁극적으로 원래의 명령어 스트림의 순서의 결과를 발생시킨다. 추측 실행을 가능하게 하기 위해서, P6 프로세서 마이크로아키텍처는 dispatch와 execution 명령어를 약속된 결과로부터 분리했다. 프로세서의 비순차적 실행 코어는 데이터 흐름 분석은 명령어 풀 내의 모든 가능한 명령어들을 사용하고 결과를 임시 레지스터에 저장한다. 그리고 retirement unit은 명령어 풀에서 더이상 데이터 의존성이 없는 완료된 명령어들을 다른 명령어들과 아직 해결되지 않은 분기 예측과 함께 선형적으로 찾아본다. 완료된 명령어가 발견됬을 떄 retirement unit은 명령어의 결과를 메모리나 IA-32레지스터(이때 프로세서의 8개의 범용 레지스터와 8개의 x87 FPU 데이터 레지스터가 쓰인다)에 변경을 확정짓는다 그것들의 명령어 풀에서 원래 발생시키고 탈락한 명령어 순서대로.
## 2.2.2 Intel NetBurst® Microarchitecture
인텔 NetBurst 마이크로아키텍처에는 다음과 같은 기능을 제공한다:
- 빠른 실행 엔진
    - ALU가 클럭당 두번 실행됨
    - 기본적인 정수 연산은 1/2 클럭만에 dispatch됨
- 하이퍼 파이프라인 기술
    - 깊은 파이프라인은 desktop PC와 서버에서 업계 최고의 클럭률을 가능하게 한다
    - Frequency headroom과 확장성은 계속해서 미래에도 업계를 이끌것이다
- ADE(Advanced Dynamic Execution)
    - 깊은, 비순차적 명령 실행, 추측 실행 엔진
        - 최대 126개의 명령어 처리 가능
        - 최대 파이프라인에 대한 48개의 읽기 및 24개의 쓰기
    - 향상된 분기 예측 능력
        - 깊은 파이프라인에 할당된 예측 실패 패널티를 줄여줌
        - 향상된 분기 예측 알고리즘
        - 4K개의 분기 target array(명령어 실행되는 과정을 저장)
- 새로운 캐시 서브시스템
    - L1 캐시
        - 향상된 실행 추적 캐시는 디코드된 명령어를 저장
        - 실행 추적 캐시는 메인 실행 루프의 해독 지연시간을 제거
        - 실행 추적 캐시는 프로그램 실행 흐름을 한줄로 통합
        - 적은 지연시간의 데이터 캐시
    - L2 캐시
        - 최고 속도, 확장가능한 버스 클럭으로 최대 4배의 실제 성능 향상
        - 프로세서 클럭과 함께 대역폭과 성능향상
- NetBurst 마이크로아키텍처 시스템 버스를 위한 고성능, quad-pumped 버스 인터페이스
    - quad-pumped, 확장가능한 버스 클럭을 지원해서 4배의 성능 향상을 달성
    - 초당 8.5GB/s 전송 가능
- 병렬화를 가능하게 하는 슈퍼스칼라 이슈
- 레지스터 이름 공간 제한을 피하기 위해 확장된 하드웨어 레지스터 의 이름 변경
- 64byte 캐시 라인 사이즈 (최대 섹터당 두줄의 데이터를 전송 가능)
### 2.2.2.1 The Front End Pipeline
front end 부분은 비순차적 명령 실행 코어를 위한 프로그램의 명령어를 제공한다. 이건 많은 기능들을 수행한다:
- 실행될만한 명령 미리 가져오기 (prefetch)
- prefetch되지 않은 명령어 가져오기
- micro-operation으로 명령어 해독
- 복잡한 명령어를 위한 마이크로코드와 특수 목적 코드 생성
- execution trace cache에 있는 복호화된 명령어 전달
- 매우 향상된 알고리즘을 사용한 분기 예측
그 파이프라인은 고속의 파이프라인 마이크로아키텍처의 흔한 문제를 부르게 만들어졌다. 이 두 문제들은 지연의 주된 원인을 기여한다:
- 타깃으로부터 fetch되어진 명령어를 해석하는 시간
- 분기 또는 분기 타깃이 캐시 라인의 중간에 있어서 생기는 해석 대역폭 낭비
파이프라인의 추적 캐시 작업은 이러한 문제점을 발생시킨다. 명령어들은 지속적으로 fetch되고 decode된다 translation engine에 의해서(fetch/decode logic 부분 참고) 그리고 micro-ops의 배열로 만들어지는데 이걸 추적(trace)이라고 부른다. 언제나, 다중 추적들은 (prefetched branch를 가르킨다) trace 캐시에 저장이 되어진다. trace cache는 활성화된 분기를 따라가는 명령어들을 위해 검색된다. 만약 명령어가 pre-fetch된 분기의 첫 명령어로 보여진다면 매모리 계층의 명령어 fetch와 decode가 중단되고 그 pre-fetch된 분기는 새로운 명령어들의 근원이 된다(Figure 2-2 참조).

추적 캐시와 번역 엔진은 협력하는 분기 예측 하드웨어를 가지고 있다. 분기 목표물은 Branch Target Buffers를 사용해서 그들의 선형 주소 위에서 예측이되고, 가능한한 빨리 fetch된다.

### 2.2.2.2 Out-Of-Order Execution Core
비순차적 실행 코어의 미순차적 명령어 실행 능력은 병렬화를 가능케 하는 주된 요소다. 이 기능은 프로세서가 한 micro-op이 지연됬을때 명령어들을 재정렬 하게 해준고, 다른 micro-op들은 그 이후에 진행될 것이다. 프로세서는 micro-op들의 부드러운 흐름을 위해서 몇몇 버퍼들을 사용한다.

코어는 병렬 실행이 가능하게 디자인되었다. 코어는 사이클마다 최대 6개의 micro-op들을 가져올 수 있다 (하지만 이건 추적캐시와 micro-op 대역폭의 retirement를 초과한다). 대부분의 파이프라인들은 매 사이클마다 새로운 micro-op을 실행하는걸 시작할 수 있어서, 몇몇 명령어들은 각각의 파이프라인에서 동시에 실행될 수 있다. 수많은 ALU명령어들은 한 사이클에 두개씩 시작할 수 있다; 하지만 많은 부동소수점 명령어들은 2 사이클에 한번만 실행될 수 있다.

### 2.2.2.3 Retirement Unit
